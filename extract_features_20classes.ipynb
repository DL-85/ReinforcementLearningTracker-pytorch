{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import deepdish as dd\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import vgg16\n",
    "from scipy.misc import imread, imresize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gpu usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "S = 8\n",
    "B = 2\n",
    "C = 20\n",
    "n_features = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = vgg16(pretrained=False)\n",
    "model.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, n_features),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(n_features, (B*5+C) * S * S),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "model.load_state_dict(torch.load('./results/model_100iters_S8_1000feas_vot20classes_fixlossbug.pth'))\n",
    "model.eval()\n",
    "if use_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = dd.io.load('./routine_generate_vot2017_train/normal_bboxes_all_sqrtwh_list.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(325, 4)\n",
      "(196, 4)\n",
      "(105, 4)\n",
      "(725, 4)\n",
      "(339, 4)\n",
      "(225, 4)\n",
      "(76, 4)\n",
      "(350, 4)\n",
      "(175, 4)\n",
      "(151, 4)\n",
      "(742, 4)\n",
      "(345, 4)\n",
      "(160, 4)\n",
      "(131, 4)\n",
      "(326, 4)\n",
      "(355, 4)\n",
      "(292, 4)\n",
      "(366, 4)\n",
      "(1377, 4)\n",
      "(248, 4)\n"
     ]
    }
   ],
   "source": [
    "for item in bboxes:\n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bboxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(vot_folder, model, n_features, save_path, bboxes, padzero, use_gpu):\n",
    "    whole_combo_list = []\n",
    "    zero_padding = torch.FloatTensor([0,0,0,0])\n",
    "    file = os.path.join(vot_folder, 'list_20classes.txt')\n",
    "    CLASSES = [line.rstrip('\\n') for line in open(file)]\n",
    "    \n",
    "    for index, CLASS in enumerate(CLASSES):\n",
    "        sys.stdout.write('%s/20\\r' % str(index + 1))\n",
    "        sys.stdout.flush()\n",
    "        subdirpath = os.path.join(vot_folder, CLASS)\n",
    "        n_data = len(fnmatch.filter(os.listdir(subdirpath), '*.jpg'))\n",
    "        data_series = np.arange(n_data)\n",
    "        file_numbers = data_series + 1\n",
    "        combo_list = []\n",
    "        for i, numble in enumerate(file_numbers):\n",
    "            jpgname = '{0:08}'.format(numble) + '.jpg'\n",
    "            jpgpath = os.path.join(subdirpath, jpgname)\n",
    "            img = imread(jpgpath)\n",
    "            height, width, _ = img.shape\n",
    "            bbox = bboxes[index][i] / torch.Tensor([width, height, np.sqrt(width), np.sqrt(height)])\n",
    "            \n",
    "            # 2. Create a PyTorch Variable with the transformed image\n",
    "            img = imresize(img, (224, 224))\n",
    "            transform = transforms.Compose([transforms.ToTensor(), ])\n",
    "            img = transform(img)\n",
    "            img = Variable(img[None, :, :, :], volatile=True)\n",
    "            if use_gpu:\n",
    "                img = img.cuda()\n",
    "                # 3. Create a vector of zeros that will hold our feature vector\n",
    "            #    The fc1 layer has an output size of 4096\n",
    "            features = torch.zeros(n_features)\n",
    "            # 4. Define a function that will copy the output of a layer\n",
    "            def copy_data(m, i, o):\n",
    "                features.copy_(o.data)\n",
    "            # 5. Attach that function to our selected layer\n",
    "            layer = model.classifier._modules.get('1')\n",
    "            h = layer.register_forward_hook(copy_data)\n",
    "            # 6. Run the model on our transformed image\n",
    "            model(img)\n",
    "            # 7. Detach our copy function from the layer\n",
    "            h.remove()\n",
    "            # 8. padzero or not with features\n",
    "            if padzero is True:\n",
    "                if index ==0:\n",
    "                    combo = torch.cat([features, bbox], dim=0)\n",
    "                else:\n",
    "                    combo = torch.cat([features, zero_padding], dim=0)\n",
    "            else:\n",
    "                combo = torch.cat([features, bbox], dim=0)\n",
    "            combo_list.append(combo)\n",
    "            #combo_list = np.array(combo_list, dtype=np.float32)\n",
    "        for i in range(len(combo_list)):\n",
    "            if i == 0:\n",
    "                cat_features = combo_list[0].view(1,-1)\n",
    "            else:\n",
    "                cat_features = torch.cat((cat_features, combo_list[i].view(1,-1)))\n",
    "                \n",
    "        whole_combo_list.append(cat_features)\n",
    "        \n",
    "    if padzero is True:\n",
    "        dd.io.save(os.path.join(save_path, '20classes_combo_padzero_1000features.h5'), whole_combo_list)\n",
    "    else:\n",
    "        dd.io.save(os.path.join(save_path, '20classes_combo_padgt_1000features.h5'), whole_combo_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = './routine_generate_vot2017_train/'\n",
    "vot_folder = './routine_generate_vot2017_train/vot2017/'\n",
    "padzero = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/20\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlcv1718/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: src is not broadcastable to dst, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20\r"
     ]
    }
   ],
   "source": [
    "extract_features(vot_folder, model, n_features, save_path, bboxes, padzero, use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/20\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlcv1718/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: src is not broadcastable to dst, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20\r"
     ]
    }
   ],
   "source": [
    "padzero = False\n",
    "extract_features(vot_folder, model, n_features, save_path, bboxes, padzero, use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load bboxes list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bboxes_padzeros = dd.io.load(os.path.join(save_path, '20classes_combo_padzero.h5'))\n",
    "bboxes_padgt = dd.io.load(os.path.join(save_path, '20classes_combo_padgt.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bboxes_padzeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([325, 4100])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes_padzeros[0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### normalize bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = os.path.join(vot_folder, 'list_20classes.txt')\n",
    "CLASSES = [line.rstrip('\\n') for line in open(file)]\n",
    "normalized_bbox = np.zeros_like(bboxes)\n",
    "for index, CLASS in enumerate(CLASSES):\n",
    "    sys.stdout.write('%s/500\\r' % str(index + 1))\n",
    "    sys.stdout.flush()\n",
    "    #print(index)\n",
    "    img = imread(save_path+image_name)\n",
    "    height, width, _ = img.shape\n",
    "    normalized_bbox[index] = bboxes[index] / np.array([width, height, width, height])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
